{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir semeval25-unlearning-model; mkdir semeval25-unlearning-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from huggingface_hub import snapshot_download\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# hf_token = \"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\"\n",
    "\n",
    "# ## Fetch and load model:\n",
    "# snapshot_download(repo_id='llmunlearningsemeval2025organization/olmo-finetuned-semeval25-unlearning', token=hf_token, local_dir='semeval25-unlearning-model')\n",
    "# model = AutoModelForCausalLM.from_pretrained('semeval25-unlearning-model')\n",
    " \n",
    "# ## Fetch and load dataset:\n",
    "# snapshot_download(repo_id='llmunlearningsemeval2025organization/semeval25-unlearning-dataset-public', token=hf_token, local_dir='semeval25-unlearning-data', repo_type=\"dataset\")\n",
    "# retain_train_df = pd.read_parquet('semeval25-unlearning-data/data/retain_train-00000-of-00001.parquet', engine='pyarrow') # Retain split: train set\n",
    "# retain_validation_df = pd.read_parquet('semeval25-unlearning-data/data/retain_validation-00000-of-00001.parquet', engine='pyarrow') # Retain split: validation set\n",
    "# forget_train_df = pd.read_parquet('semeval25-unlearning-data/data/forget_train-00000-of-00001.parquet', engine='pyarrow') # Forget split: train set\n",
    "# forget_validation_df = pd.read_parquet('semeval25-unlearning-data/data/forget_validation-00000-of-00001.parquet', engine='pyarrow') # Forget split: validation set\n",
    "# !mkdir train validation\n",
    "# retain_train_df.to_json('train/retain.jsonl'); forget_train_df.to_json('train/forget.jsonl')\n",
    "# retain_validation_df.to_json('validation/retain.jsonl'); forget_validation_df.to_json('validation/forget.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONLDataset(Dataset):\n",
    "    def __init__(self, jsonl_path, tokenizer, max_length=256):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Load the data from the JSONL file\n",
    "        with open(jsonl_path, \"r\", encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    item = json.loads(line.strip())\n",
    "                    # Ensure the input is a string\n",
    "                    document = str(item.get(\"input\", \"\")).strip()\n",
    "                    task = str(item.get(\"split\", \"\")).strip()\n",
    "                    \n",
    "                    if document:  # Only append if document is not empty\n",
    "                        self.data.append({\n",
    "                            \"input\": document,\n",
    "                            \"task\": task\n",
    "                        })\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Skipping invalid JSON line: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {e}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} items from {jsonl_path}\")\n",
    "        if len(self.data) > 0:\n",
    "            print(f\"Sample input text: {self.data[0]['input'][:100]}...\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            # Ensure input is a string\n",
    "            text = str(item[\"input\"])\n",
    "            \n",
    "            # Tokenize the input\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=None  # Changed from \"pt\" to None\n",
    "            )\n",
    "            \n",
    "            # Convert to tensors\n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n",
    "                \"task\": item[\"task\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {e}\")\n",
    "            print(f\"Problematic input: {item['input']}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from typing import Dict, List, Tuple\n",
    "import json\n",
    "import os\n",
    "\n",
    "class SemanticMemoryBank:\n",
    "    def __init__(self, size=1000):\n",
    "        self.size = size\n",
    "        self.forget_embeddings = []\n",
    "        self.retain_embeddings = []\n",
    "    \n",
    "    def update(self, forget_emb, retain_emb):\n",
    "        self.forget_embeddings.extend(forget_emb)\n",
    "        self.retain_embeddings.extend(retain_emb)\n",
    "        \n",
    "        if len(self.forget_embeddings) > self.size:\n",
    "            self.forget_embeddings = self.forget_embeddings[-self.size:]\n",
    "        if len(self.retain_embeddings) > self.size:\n",
    "            self.retain_embeddings = self.retain_embeddings[-self.size:]\n",
    "\n",
    "class EnhancedUnlearning:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        memory_bank_size: int = 1000,\n",
    "        temperature: float = 0.07,\n",
    "        forget_weight: float = 1.0,\n",
    "        retain_weight: float = 0.5,\n",
    "        contrastive_weight: float = 0.3,\n",
    "        beta: float = 1.0,\n",
    "        reference_model: AutoModelForCausalLM = None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.memory_bank = SemanticMemoryBank(size=memory_bank_size)\n",
    "        self.temperature = temperature\n",
    "        self.forget_weight = forget_weight\n",
    "        self.retain_weight = retain_weight\n",
    "        self.contrastive_weight = contrastive_weight\n",
    "        self.beta = beta\n",
    "        self.reference_model = reference_model\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "    def get_semantic_embedding(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            last_hidden = outputs.hidden_states[-1]\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size())\n",
    "            sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "            return sum_embeddings / sum_mask\n",
    "\n",
    "    def contrastive_loss(self, anchor, positive, negative):\n",
    "        anchor_norm = F.normalize(anchor, dim=1)\n",
    "        positive_norm = F.normalize(positive, dim=1)\n",
    "        negative_norm = F.normalize(negative, dim=1)\n",
    "        \n",
    "        pos_sim = torch.matmul(anchor_norm, positive_norm.t()) / self.temperature\n",
    "        neg_sim = torch.matmul(anchor_norm, negative_norm.t()) / self.temperature\n",
    "        \n",
    "        logits = torch.cat([pos_sim, neg_sim], dim=1)\n",
    "        labels = torch.zeros(anchor.size(0), device=anchor.device, dtype=torch.long)\n",
    "        \n",
    "        return F.cross_entropy(logits, labels)\n",
    "\n",
    "    def compute_npo_loss(self, model_probs, ref_probs):\n",
    "        \"\"\"Compute NPO-based loss for probability ratio optimization\"\"\"\n",
    "        ratio = model_probs / (ref_probs + 1e-10)\n",
    "        return -2 / self.beta * torch.log(1 + (ratio ** (-self.beta)))\n",
    "\n",
    "    def unlearning_step(\n",
    "        self,\n",
    "        forget_batch: Dict[str, torch.Tensor],\n",
    "        retain_batch: Dict[str, torch.Tensor],\n",
    "        optimizer: torch.optim.Optimizer\n",
    "    ) -> Tuple[float, float, float, float]:\n",
    "        self.model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        device = next(self.model.parameters()).device\n",
    "        forget_batch = {k: v.to(device) for k, v in forget_batch.items()}\n",
    "        retain_batch = {k: v.to(device) for k, v in retain_batch.items()}\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # 1. Semantic embeddings\n",
    "            forget_emb = self.get_semantic_embedding(\n",
    "                forget_batch[\"input_ids\"],\n",
    "                forget_batch[\"attention_mask\"]\n",
    "            )\n",
    "            retain_emb = self.get_semantic_embedding(\n",
    "                retain_batch[\"input_ids\"],\n",
    "                retain_batch[\"attention_mask\"]\n",
    "            )\n",
    "            \n",
    "            # 2. Update memory bank\n",
    "            self.memory_bank.update([forget_emb.detach()], [retain_emb.detach()])\n",
    "            \n",
    "            # 3. Get model outputs\n",
    "            forget_outputs = self.model(**forget_batch)\n",
    "            retain_outputs = self.model(**retain_batch)\n",
    "            \n",
    "            # 4. Compute NPO losses if reference model is available\n",
    "            if self.reference_model is not None:\n",
    "                with torch.no_grad():\n",
    "                    ref_forget = self.reference_model(**forget_batch)\n",
    "                    ref_retain = self.reference_model(**retain_batch)\n",
    "                \n",
    "                # Compute probabilities for NPO\n",
    "                forget_probs = F.softmax(forget_outputs.logits, dim=-1)\n",
    "                retain_probs = F.softmax(retain_outputs.logits, dim=-1)\n",
    "                ref_forget_probs = F.softmax(ref_forget.logits, dim=-1)\n",
    "                ref_retain_probs = F.softmax(ref_retain.logits, dim=-1)\n",
    "                \n",
    "                # Get target token probabilities\n",
    "                target_tokens = forget_batch[\"input_ids\"][:, -1].unsqueeze(1).unsqueeze(2)\n",
    "                forget_token_probs = forget_probs.gather(2, target_tokens).squeeze(-1)\n",
    "                ref_forget_token_probs = ref_forget_probs.gather(2, target_tokens).squeeze(-1)\n",
    "                \n",
    "                npo_forget_loss = self.compute_npo_loss(forget_token_probs, ref_forget_token_probs).mean()\n",
    "                forget_loss = (npo_forget_loss + forget_outputs.loss) * self.forget_weight\n",
    "            else:\n",
    "                forget_loss = forget_outputs.loss * self.forget_weight\n",
    "            \n",
    "            # 5. Retain loss\n",
    "            retain_loss = retain_outputs.loss * self.retain_weight\n",
    "            \n",
    "            # 6. Contrastive loss\n",
    "            if len(self.memory_bank.forget_embeddings) > 0 and len(self.memory_bank.retain_embeddings) > 0:\n",
    "                forget_memory = torch.stack(self.memory_bank.forget_embeddings)\n",
    "                retain_memory = torch.stack(self.memory_bank.retain_embeddings)\n",
    "                contrast_loss = self.contrastive_loss(\n",
    "                    forget_emb,\n",
    "                    retain_memory,\n",
    "                    forget_memory\n",
    "                ) * self.contrastive_weight\n",
    "            else:\n",
    "                contrast_loss = torch.tensor(0.0, device=device)\n",
    "            \n",
    "            # 7. Total loss\n",
    "            total_loss = -forget_loss + retain_loss + contrast_loss\n",
    "\n",
    "        # 8. Backward pass with gradient scaling\n",
    "        self.scaler.scale(total_loss).backward()\n",
    "        self.scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "        self.scaler.step(optimizer)\n",
    "        self.scaler.update()\n",
    "        \n",
    "        return (\n",
    "            forget_loss.item(),\n",
    "            retain_loss.item(),\n",
    "            contrast_loss.item(),\n",
    "            total_loss.item()\n",
    "        )\n",
    "\n",
    "    def unlearn(\n",
    "        self,\n",
    "        forget_loader: DataLoader,\n",
    "        retain_loader: DataLoader,\n",
    "        num_epochs: int = 3,\n",
    "        learning_rate: float = 1e-5,\n",
    "        gradient_accumulation_steps: int = 2,\n",
    "        output_path: str = None\n",
    "    ):\n",
    "        \"\"\"Main unlearning loop\"\"\"\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)\n",
    "        device = next(self.model.parameters()).device\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            total_forget_loss = 0\n",
    "            total_retain_loss = 0\n",
    "            total_contrast_loss = 0\n",
    "            total_steps = 0\n",
    "            \n",
    "            from itertools import zip_longest\n",
    "            for i, (forget_batch, retain_batch) in enumerate(zip_longest(forget_loader, retain_loader)):\n",
    "                if forget_batch is None or retain_batch is None:\n",
    "                    continue\n",
    "                \n",
    "                losses = self.unlearning_step(forget_batch, retain_batch, optimizer)\n",
    "                \n",
    "                total_forget_loss += losses[0]\n",
    "                total_retain_loss += losses[1]\n",
    "                total_contrast_loss += losses[2]\n",
    "                total_steps += 1\n",
    "                \n",
    "                if (i + 1) % gradient_accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Print epoch statistics\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Average Forget Loss: {total_forget_loss/total_steps:.4f}\")\n",
    "            print(f\"Average Retain Loss: {total_retain_loss/total_steps:.4f}\")\n",
    "            print(f\"Average Contrast Loss: {total_contrast_loss/total_steps:.4f}\")\n",
    "        \n",
    "        if output_path:\n",
    "            self.model.save_pretrained(output_path)\n",
    "            self.tokenizer.save_pretrained(output_path)\n",
    "            print(f\"Model saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import gc\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "class JSONLDataset(Dataset):\n",
    "    def __init__(self, jsonl_path, tokenizer, max_length=256):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(jsonl_path, \"r\", encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    item = json.loads(line.strip())\n",
    "                    input_dict = item.get('input', {})\n",
    "                    \n",
    "                    for idx in sorted(input_dict.keys()):\n",
    "                        text = str(input_dict[idx])\n",
    "                        if text:\n",
    "                            self.data.append({\n",
    "                                \"input\": text,\n",
    "                                \"task\": item.get('task', {}).get(idx, \"default\")\n",
    "                            })\n",
    "                            \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Skipping invalid JSON line: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {e}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} items from {jsonl_path}\")\n",
    "        if len(self.data) > 0:\n",
    "            print(f\"Sample input text: {self.data[0]['input'][:100]}...\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            inputs = self.tokenizer(\n",
    "                item[\"input\"],\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=None\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {e}\")\n",
    "            raise\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "def setup_unlearning(\n",
    "    model_path: str,\n",
    "    tokenizer_name: str,\n",
    "    retain_path: str,\n",
    "    forget_path: str,\n",
    "    batch_size: int = 1,\n",
    "    max_length: int = 256\n",
    "):\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            llm_int8_enable_fp32_cpu_offload=True\n",
    "        )\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "\n",
    "        reference_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "\n",
    "        retain_dataset = JSONLDataset(retain_path, tokenizer, max_length)\n",
    "        forget_dataset = JSONLDataset(forget_path, tokenizer, max_length)\n",
    "\n",
    "        retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)\n",
    "        forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        return model, reference_model, tokenizer, retain_loader, forget_loader\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during setup: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "class EnhancedUnlearning:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        memory_bank_size=1000,\n",
    "        temperature=0.07,\n",
    "        forget_weight=1.0,\n",
    "        retain_weight=0.5,\n",
    "        contrastive_weight=0.3,\n",
    "        beta=1.0,\n",
    "        reference_model=None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.memory_bank = SemanticMemoryBank(size=memory_bank_size)\n",
    "        self.temperature = temperature\n",
    "        self.forget_weight = forget_weight\n",
    "        self.retain_weight = retain_weight\n",
    "        self.contrastive_weight = contrastive_weight\n",
    "        self.beta = beta\n",
    "        self.reference_model = reference_model\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    def get_semantic_embedding(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            last_hidden = outputs.hidden_states[-1]\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size())\n",
    "            sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "            return sum_embeddings / sum_mask\n",
    "\n",
    "    def contrastive_loss(self, anchor, positive, negative):\n",
    "        anchor_norm = F.normalize(anchor, dim=1)\n",
    "        positive_norm = F.normalize(positive, dim=1)\n",
    "        negative_norm = F.normalize(negative, dim=1)\n",
    "        \n",
    "        pos_sim = torch.matmul(anchor_norm, positive_norm.t()) / self.temperature\n",
    "        neg_sim = torch.matmul(anchor_norm, negative_norm.t()) / self.temperature\n",
    "        \n",
    "        logits = torch.cat([pos_sim, neg_sim], dim=1)\n",
    "        labels = torch.zeros(anchor.size(0), device=anchor.device, dtype=torch.long)\n",
    "        \n",
    "        return F.cross_entropy(logits, labels)\n",
    "\n",
    "    def compute_npo_loss(self, model_probs, ref_probs):\n",
    "        \"\"\"Compute NPO-based loss for probability ratio optimization\"\"\"\n",
    "        ratio = model_probs / (ref_probs + 1e-10)\n",
    "        return -2 / self.beta * torch.log(1 + (ratio ** (-self.beta)))\n",
    "\n",
    "    def unlearning_step(self, forget_batch, retain_batch, optimizer):\n",
    "        self.model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        forget_batch = {k: v.to(next(self.model.parameters()).device) for k, v in forget_batch.items()}\n",
    "        retain_batch = {k: v.to(next(self.model.parameters()).device) for k, v in retain_batch.items()}\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            forget_outputs = self.model(**forget_batch)\n",
    "            retain_outputs = self.model(**retain_batch)\n",
    "            \n",
    "            if self.reference_model:\n",
    "                with torch.no_grad():\n",
    "                    ref_forget = self.reference_model(**forget_batch)\n",
    "                    \n",
    "                forget_probs = torch.softmax(forget_outputs.logits, dim=-1)\n",
    "                ref_forget_probs = torch.softmax(ref_forget.logits, dim=-1)\n",
    "                \n",
    "                npo_forget_loss = self.compute_npo_loss(forget_probs, ref_forget_probs)\n",
    "                forget_loss = npo_forget_loss * self.forget_weight\n",
    "            else:\n",
    "                forget_loss = forget_outputs.logits.mean() * self.forget_weight\n",
    "            \n",
    "            retain_loss = retain_outputs.logits.mean() * self.retain_weight\n",
    "            total_loss = -forget_loss + retain_loss\n",
    "\n",
    "        self.scaler.scale(total_loss).backward()\n",
    "        self.scaler.step(optimizer)\n",
    "        self.scaler.update()\n",
    "        \n",
    "        return forget_loss.item(), retain_loss.item(), 0, total_loss.item()\n",
    "\n",
    "    def unlearn(\n",
    "        self,\n",
    "        forget_loader: DataLoader,\n",
    "        retain_loader: DataLoader,\n",
    "        num_epochs: int = 3,\n",
    "        learning_rate: float = 1e-5,\n",
    "        gradient_accumulation_steps: int = 2,\n",
    "        output_path: str = None\n",
    "    ):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            total_forget_loss = 0\n",
    "            total_retain_loss = 0\n",
    "            total_contrast_loss = 0\n",
    "            total_steps = 0\n",
    "            \n",
    "            for i, (forget_batch, retain_batch) in enumerate(zip(forget_loader, retain_loader)):\n",
    "                if forget_batch is None or retain_batch is None:\n",
    "                    continue\n",
    "                \n",
    "                losses = self.unlearning_step(forget_batch, retain_batch, optimizer)\n",
    "                \n",
    "                total_forget_loss += losses[0]\n",
    "                total_retain_loss += losses[1]\n",
    "                total_contrast_loss += losses[2]\n",
    "                total_steps += 1\n",
    "                \n",
    "                if (i + 1) % gradient_accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Average Forget Loss: {total_forget_loss/total_steps:.4f}\")\n",
    "            print(f\"Average Retain Loss: {total_retain_loss/total_steps:.4f}\")\n",
    "            print(f\"Average Contrast Loss: {total_contrast_loss/total_steps:.4f}\")\n",
    "        \n",
    "        if output_path:\n",
    "            self.model.save_pretrained(output_path)\n",
    "            self.tokenizer.save_pretrained(output_path)\n",
    "            print(f\"Model saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046d0f9b99f44ddb8eb3fb6ba05b813d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bcd8b1954b4744bb38512d5d3242de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1136 items from /teamspace/studios/this_studio/train/retain.jsonl\n",
      "Sample input text: Fredericka Amber was born on December 21, 1969. Her Social Security number is 900-22-6238 and her ph...\n",
      "Loaded 1112 items from /teamspace/studios/this_studio/train/forget.jsonl\n",
      "Sample input text: In the mystical city of Deadesius, where magic and mystery intertwined, two sorceresses, Marcile and...\n",
      "\n",
      "Error during setup or training: grad can be implicitly created only for scalar outputs\n",
      "\n",
      "Debugging information:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1646/454195701.py\", line 24, in <module>\n",
      "    unlearner.unlearn(\n",
      "  File \"/tmp/ipykernel_1646/2073610325.py\", line 214, in unlearn\n",
      "    losses = self.unlearning_step(forget_batch, retain_batch, optimizer)\n",
      "  File \"/tmp/ipykernel_1646/2073610325.py\", line 187, in unlearning_step\n",
      "    self.scaler.scale(total_loss).backward()\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 259, in backward\n",
      "    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 132, in _make_grads\n",
      "    raise RuntimeError(\n",
      "RuntimeError: grad can be implicitly created only for scalar outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'semeval25-unlearning-model'\n",
    "    tokenizer_name = 'allenai/OLMo-1B-0724-hf'\n",
    "    retain_path = \"/teamspace/studios/this_studio/train/retain.jsonl\"\n",
    "    forget_path = \"/teamspace/studios/this_studio/train/forget.jsonl\"\n",
    "\n",
    "    try:\n",
    "        model, reference_model, tokenizer, retain_loader, forget_loader = setup_unlearning(\n",
    "            model_path=model_path,\n",
    "            tokenizer_name=tokenizer_name,\n",
    "            retain_path=retain_path,\n",
    "            forget_path=forget_path,\n",
    "            batch_size=1\n",
    "        )\n",
    "\n",
    "        unlearner = EnhancedUnlearning(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            reference_model=reference_model,\n",
    "            beta=1.0,\n",
    "            memory_bank_size=1000\n",
    "        )\n",
    "\n",
    "        unlearner.unlearn(\n",
    "            forget_loader=forget_loader,\n",
    "            retain_loader=retain_loader,\n",
    "            num_epochs=3,\n",
    "            learning_rate=1e-5,\n",
    "            output_path=\"./unlearned_model\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during setup or training: {str(e)}\")\n",
    "        print(\"\\nDebugging information:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.45.0)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bitsandbytes) (2.2.1+cu121)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import gc\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "class JSONLDataset(Dataset):\n",
    "    def __init__(self, jsonl_path, tokenizer, max_length=256):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(jsonl_path, \"r\", encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    item = json.loads(line.strip())\n",
    "                    input_dict = item.get('input', {})\n",
    "                    \n",
    "                    for idx in sorted(input_dict.keys()):\n",
    "                        text = str(input_dict[idx])\n",
    "                        if text:\n",
    "                            self.data.append({\n",
    "                                \"input\": text,\n",
    "                                \"task\": item.get('task', {}).get(idx, \"default\")\n",
    "                            })\n",
    "                            \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Skipping invalid JSON line: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {e}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} items from {jsonl_path}\")\n",
    "        if len(self.data) > 0:\n",
    "            print(f\"Sample input text: {self.data[0]['input'][:100]}...\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            inputs = self.tokenizer(\n",
    "                item[\"input\"],\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=None\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {e}\")\n",
    "            raise\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "def setup_unlearning(\n",
    "    model_path: str,\n",
    "    tokenizer_name: str,\n",
    "    retain_path: str,\n",
    "    forget_path: str,\n",
    "    batch_size: int = 1,\n",
    "    max_length: int = 256\n",
    "):\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            llm_int8_enable_fp32_cpu_offload=True\n",
    "        )\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "\n",
    "        reference_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            quantization_config=quantization_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16\n",
    "        )\n",
    "\n",
    "        retain_dataset = JSONLDataset(retain_path, tokenizer, max_length)\n",
    "        forget_dataset = JSONLDataset(forget_path, tokenizer, max_length)\n",
    "\n",
    "        retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)\n",
    "        forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        return model, reference_model, tokenizer, retain_loader, forget_loader\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during setup: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "class SemanticMemoryBank:\n",
    "    def __init__(self, size=1000):\n",
    "        self.size = size\n",
    "        self.forget_embeddings = []\n",
    "        self.retain_embeddings = []\n",
    "    \n",
    "    def update(self, forget_emb, retain_emb):\n",
    "        self.forget_embeddings.extend(forget_emb)\n",
    "        self.retain_embeddings.extend(retain_emb)\n",
    "        \n",
    "        if len(self.forget_embeddings) > self.size:\n",
    "            self.forget_embeddings = self.forget_embeddings[-self.size:]\n",
    "        if len(self.retain_embeddings) > self.size:\n",
    "            self.retain_embeddings = self.retain_embeddings[-self.size:]\n",
    "\n",
    "\n",
    "class EnhancedUnlearning:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        memory_bank_size=1000,\n",
    "        temperature=0.07,\n",
    "        forget_weight=1.0,\n",
    "        retain_weight=0.5,\n",
    "        contrastive_weight=0.3,\n",
    "        beta=1.0,\n",
    "        reference_model=None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.tokenizer = tokenizer\n",
    "        self.memory_bank = SemanticMemoryBank(size=memory_bank_size)\n",
    "        self.temperature = temperature\n",
    "        self.forget_weight = forget_weight\n",
    "        self.retain_weight = retain_weight\n",
    "        self.contrastive_weight = contrastive_weight\n",
    "        self.beta = beta\n",
    "        self.reference_model = reference_model\n",
    "        self.scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    def get_semantic_embedding(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            last_hidden = outputs.hidden_states[-1]\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size())\n",
    "            sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "            return sum_embeddings / sum_mask\n",
    "\n",
    "    def contrastive_loss(self, anchor, positive, negative):\n",
    "        anchor_norm = F.normalize(anchor, dim=1)\n",
    "        positive_norm = F.normalize(positive, dim=1)\n",
    "        negative_norm = F.normalize(negative, dim=1)\n",
    "        \n",
    "        pos_sim = torch.matmul(anchor_norm, positive_norm.t()) / self.temperature\n",
    "        neg_sim = torch.matmul(anchor_norm, negative_norm.t()) / self.temperature\n",
    "        \n",
    "        logits = torch.cat([pos_sim, neg_sim], dim=1)\n",
    "        labels = torch.zeros(anchor.size(0), device=anchor.device, dtype=torch.long)\n",
    "        \n",
    "        return F.cross_entropy(logits, labels)\n",
    "\n",
    "    def compute_npo_loss(self, model_probs, ref_probs):\n",
    "        \"\"\"Compute NPO-based loss for probability ratio optimization\"\"\"\n",
    "        ratio = model_probs / (ref_probs + 1e-10)\n",
    "        return -2 / self.beta * torch.log(1 + (ratio ** (-self.beta)))\n",
    "\n",
    "    def unlearning_step(self, forget_batch, retain_batch, optimizer):\n",
    "        self.model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move batches to appropriate device\n",
    "        device = next(self.model.parameters()).device\n",
    "        forget_batch = {k: v.to(device) for k, v in forget_batch.items()}\n",
    "        retain_batch = {k: v.to(device) for k, v in retain_batch.items()}\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Get model outputs\n",
    "            forget_outputs = self.model(**forget_batch)\n",
    "            retain_outputs = self.model(**retain_batch)\n",
    "            \n",
    "            # Calculate losses using mean reduction\n",
    "            if self.reference_model:\n",
    "                with torch.no_grad():\n",
    "                    ref_forget = self.reference_model(**forget_batch)\n",
    "                    \n",
    "                forget_probs = torch.softmax(forget_outputs.logits, dim=-1)\n",
    "                ref_forget_probs = torch.softmax(ref_forget.logits, dim=-1)\n",
    "                \n",
    "                # Make sure loss is scalar\n",
    "                npo_forget_loss = (forget_probs - ref_forget_probs).pow(2).mean()\n",
    "                forget_loss = npo_forget_loss * self.forget_weight\n",
    "            else:\n",
    "                forget_loss = forget_outputs.logits.mean() * self.forget_weight\n",
    "            \n",
    "            # Make retain loss scalar\n",
    "            retain_loss = retain_outputs.logits.mean() * self.retain_weight\n",
    "            \n",
    "            # Compute total loss\n",
    "            total_loss = (-forget_loss + retain_loss).mean()  # Ensure scalar output\n",
    "            \n",
    "        # Backward pass\n",
    "        self.scaler.scale(total_loss).backward()\n",
    "        \n",
    "        # Clip gradients if needed\n",
    "        if hasattr(self, 'max_grad_norm'):\n",
    "            self.scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "        \n",
    "        self.scaler.step(optimizer)\n",
    "        self.scaler.update()\n",
    "        \n",
    "        return (\n",
    "            forget_loss.item(),\n",
    "            retain_loss.item(),\n",
    "            0,  # No contrastive loss for now\n",
    "            total_loss.item()\n",
    "        )\n",
    "\n",
    "    def unlearn(\n",
    "        self,\n",
    "        forget_loader: DataLoader,\n",
    "        retain_loader: DataLoader,\n",
    "        num_epochs: int = 3,\n",
    "        learning_rate: float = 1e-5,\n",
    "        gradient_accumulation_steps: int = 2,\n",
    "        output_path: str = None\n",
    "    ):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            total_forget_loss = 0\n",
    "            total_retain_loss = 0\n",
    "            total_contrast_loss = 0\n",
    "            total_steps = 0\n",
    "            \n",
    "            for i, (forget_batch, retain_batch) in enumerate(zip(forget_loader, retain_loader)):\n",
    "                if forget_batch is None or retain_batch is None:\n",
    "                    continue\n",
    "                \n",
    "                losses = self.unlearning_step(forget_batch, retain_batch, optimizer)\n",
    "                \n",
    "                total_forget_loss += losses[0]\n",
    "                total_retain_loss += losses[1]\n",
    "                total_contrast_loss += losses[2]\n",
    "                total_steps += 1\n",
    "                \n",
    "                if (i + 1) % gradient_accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Average Forget Loss: {total_forget_loss/total_steps:.4f}\")\n",
    "            print(f\"Average Retain Loss: {total_retain_loss/total_steps:.4f}\")\n",
    "            print(f\"Average Contrast Loss: {total_contrast_loss/total_steps:.4f}\")\n",
    "        \n",
    "        if output_path:\n",
    "            self.model.save_pretrained(output_path)\n",
    "            self.tokenizer.save_pretrained(output_path)\n",
    "            print(f\"Model saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONLDataset(Dataset):\n",
    "    def __init__(self, jsonl_path, tokenizer, max_length=256):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(jsonl_path, \"r\", encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    item = json.loads(line.strip())\n",
    "                    input_dict = item.get('input', {})\n",
    "                    \n",
    "                    for idx in sorted(input_dict.keys()):\n",
    "                        text = str(input_dict[idx])\n",
    "                        if text:\n",
    "                            self.data.append({\n",
    "                                \"input\": text,\n",
    "                                \"task\": item.get('task', {}).get(idx, \"default\")\n",
    "                            })\n",
    "                            \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Skipping invalid JSON line: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {e}\")\n",
    "\n",
    "        print(f\"Loaded {len(self.data)} items from {jsonl_path}\")\n",
    "        if len(self.data) > 0:\n",
    "            print(f\"Sample input text: {self.data[0]['input'][:100]}...\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        try:\n",
    "            inputs = self.tokenizer(\n",
    "                item[\"input\"],\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=None\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast\n",
    "import gc\n",
    "\n",
    "def setup_unlearning(\n",
    "    model_path: str,\n",
    "    tokenizer_name: str,\n",
    "    retain_path: str,\n",
    "    forget_path: str,\n",
    "    batch_size: int = 1,\n",
    "    max_length: int = 256\n",
    "):\n",
    "    try:\n",
    "        # Clear memory\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        # Advanced quantization config\n",
    "        double_quant_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "\n",
    "        print(f\"Loading tokenizer from {tokenizer_name}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            quantization_config=double_quant_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16\n",
    "        )\n",
    "        model.gradient_checkpointing_enable()\n",
    "\n",
    "        print(\"Loading reference model\")\n",
    "        reference_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            quantization_config=double_quant_config,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16\n",
    "        )\n",
    "\n",
    "        retain_dataset = JSONLDataset(retain_path, tokenizer, max_length)\n",
    "        forget_dataset = JSONLDataset(forget_path, tokenizer, max_length)\n",
    "\n",
    "        retain_loader = DataLoader(retain_dataset, batch_size=batch_size, shuffle=True)\n",
    "        forget_loader = DataLoader(forget_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        return model, reference_model, tokenizer, retain_loader, forget_loader\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during setup: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "class EnhancedUnlearning:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        memory_bank_size=1000,\n",
    "        temperature=0.07,\n",
    "        forget_weight=1.0,\n",
    "        retain_weight=0.5,\n",
    "        contrastive_weight=0.3,\n",
    "        beta=1.0,\n",
    "        reference_model=None\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.temperature = temperature\n",
    "        self.forget_weight = forget_weight\n",
    "        self.retain_weight = retain_weight\n",
    "        self.contrastive_weight = contrastive_weight\n",
    "        self.beta = beta\n",
    "        self.reference_model = reference_model\n",
    "        self.max_grad_norm = 1.0\n",
    "\n",
    "    def compute_loss(self, outputs, labels):\n",
    "        logits = outputs.logits\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        loss = F.cross_entropy(shift_logits.view(-1, shift_logits.size(-1)), \n",
    "                             shift_labels.view(-1), \n",
    "                             reduction='mean')\n",
    "        return loss\n",
    "\n",
    "    def unlearning_step(self, forget_batch, retain_batch, optimizer):\n",
    "        self.model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        device = next(self.model.parameters()).device\n",
    "        forget_batch = {k: v.to(device) for k, v in forget_batch.items()}\n",
    "        retain_batch = {k: v.to(device) for k, v in retain_batch.items()}\n",
    "\n",
    "        with autocast(dtype=torch.bfloat16):\n",
    "            # Compute forget loss\n",
    "            forget_outputs = self.model(**forget_batch)\n",
    "            forget_loss = self.compute_loss(forget_outputs, forget_batch['input_ids'])\n",
    "            \n",
    "            if self.reference_model is not None:\n",
    "                with torch.no_grad():\n",
    "                    ref_outputs = self.reference_model(**forget_batch)\n",
    "                ref_loss = self.compute_loss(ref_outputs, forget_batch['input_ids'])\n",
    "                forget_loss = (forget_loss - ref_loss).abs().mean() * self.forget_weight\n",
    "            else:\n",
    "                forget_loss = forget_loss * self.forget_weight\n",
    "\n",
    "            # Compute retain loss\n",
    "            retain_outputs = self.model(**retain_batch)\n",
    "            retain_loss = self.compute_loss(retain_outputs, retain_batch['input_ids']) * self.retain_weight\n",
    "\n",
    "            # Total loss\n",
    "            total_loss = (-forget_loss + retain_loss).mean()\n",
    "\n",
    "        # Manual backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        return (\n",
    "            forget_loss.item(),\n",
    "            retain_loss.item(),\n",
    "            0.0,\n",
    "            total_loss.item()\n",
    "        )\n",
    "\n",
    "    def unlearn(\n",
    "        self,\n",
    "        forget_loader: DataLoader,\n",
    "        retain_loader: DataLoader,\n",
    "        num_epochs: int = 3,\n",
    "        learning_rate: float = 1e-5,\n",
    "        output_path: str = None\n",
    "    ):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            total_forget_loss = 0\n",
    "            total_retain_loss = 0\n",
    "            total_steps = 0\n",
    "            \n",
    "            for forget_batch, retain_batch in zip(forget_loader, retain_loader):\n",
    "                losses = self.unlearning_step(forget_batch, retain_batch, optimizer)\n",
    "                \n",
    "                total_forget_loss += losses[0]\n",
    "                total_retain_loss += losses[1]\n",
    "                total_steps += 1\n",
    "\n",
    "                if total_steps % 10 == 0:\n",
    "                    print(f\"Step {total_steps}: forget_loss={losses[0]:.4f}, retain_loss={losses[1]:.4f}\")\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            avg_forget_loss = total_forget_loss / total_steps\n",
    "            avg_retain_loss = total_retain_loss / total_steps\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Average Forget Loss: {avg_forget_loss:.4f}\")\n",
    "            print(f\"Average Retain Loss: {avg_retain_loss:.4f}\")\n",
    "        \n",
    "        if output_path:\n",
    "            self.model.save_pretrained(output_path)\n",
    "            self.tokenizer.save_pretrained(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer from allenai/OLMo-1B-0724-hf\n",
      "Loading model from semeval25-unlearning-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba86f2a32d94641aa41a1bf33449dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a040b2eb567f44d1ad1827e9c426fd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1136 items from /teamspace/studios/this_studio/train/retain.jsonl\n",
      "Sample input text: Fredericka Amber was born on December 21, 1969. Her Social Security number is 900-22-6238 and her ph...\n",
      "Loaded 1112 items from /teamspace/studios/this_studio/train/forget.jsonl\n",
      "Sample input text: In the mystical city of Deadesius, where magic and mystery intertwined, two sorceresses, Marcile and...\n",
      "Step 10: forget_loss=0.3388, retain_loss=7.6547\n",
      "Step 20: forget_loss=0.6909, retain_loss=7.8953\n",
      "Step 30: forget_loss=1.4393, retain_loss=7.2507\n",
      "Step 40: forget_loss=1.3568, retain_loss=7.1351\n",
      "Step 50: forget_loss=1.9899, retain_loss=1.9247\n",
      "Step 60: forget_loss=2.1625, retain_loss=6.2816\n",
      "Step 70: forget_loss=1.4600, retain_loss=6.6625\n",
      "Step 80: forget_loss=2.9014, retain_loss=6.4581\n",
      "Step 90: forget_loss=0.2990, retain_loss=6.1174\n",
      "Step 100: forget_loss=3.2637, retain_loss=6.7708\n",
      "Step 110: forget_loss=1.8208, retain_loss=5.9204\n",
      "Step 120: forget_loss=4.3596, retain_loss=6.5308\n",
      "Step 130: forget_loss=4.9296, retain_loss=2.2804\n",
      "Step 140: forget_loss=4.1912, retain_loss=5.7719\n",
      "Step 150: forget_loss=1.3097, retain_loss=5.1657\n",
      "Step 160: forget_loss=4.5510, retain_loss=2.7721\n",
      "Step 170: forget_loss=6.5131, retain_loss=4.6705\n",
      "Step 180: forget_loss=6.6923, retain_loss=4.7109\n",
      "Step 190: forget_loss=3.2825, retain_loss=4.6718\n",
      "Step 200: forget_loss=1.7862, retain_loss=3.8636\n",
      "Step 210: forget_loss=6.8028, retain_loss=4.2028\n",
      "Step 220: forget_loss=7.5171, retain_loss=4.0616\n",
      "Step 230: forget_loss=8.0966, retain_loss=3.4121\n",
      "Step 240: forget_loss=0.5559, retain_loss=4.0922\n",
      "Step 250: forget_loss=2.9162, retain_loss=4.3405\n",
      "Step 260: forget_loss=7.4263, retain_loss=0.2606\n",
      "Step 270: forget_loss=2.1954, retain_loss=4.4767\n",
      "Step 280: forget_loss=6.8598, retain_loss=1.0251\n",
      "Step 290: forget_loss=6.4163, retain_loss=1.3293\n",
      "Step 300: forget_loss=9.2832, retain_loss=0.7458\n",
      "Step 310: forget_loss=11.0726, retain_loss=2.8288\n",
      "Step 320: forget_loss=9.0798, retain_loss=0.9345\n",
      "Step 330: forget_loss=9.6394, retain_loss=2.2615\n",
      "Step 340: forget_loss=8.8520, retain_loss=2.0388\n",
      "Step 350: forget_loss=10.2332, retain_loss=0.9738\n",
      "Step 360: forget_loss=10.2466, retain_loss=3.8232\n",
      "Step 370: forget_loss=10.6874, retain_loss=0.9783\n",
      "Step 380: forget_loss=11.1823, retain_loss=1.5962\n",
      "Step 390: forget_loss=7.8764, retain_loss=2.1832\n",
      "Step 400: forget_loss=11.0099, retain_loss=1.7659\n",
      "Step 410: forget_loss=4.1741, retain_loss=0.4032\n",
      "Step 420: forget_loss=12.3356, retain_loss=0.9673\n",
      "Step 430: forget_loss=14.0872, retain_loss=0.3547\n",
      "Step 440: forget_loss=12.2818, retain_loss=1.1824\n",
      "Step 450: forget_loss=11.9076, retain_loss=1.6101\n",
      "Step 460: forget_loss=12.0547, retain_loss=1.5433\n",
      "Step 470: forget_loss=12.9095, retain_loss=1.0815\n",
      "Step 480: forget_loss=12.5556, retain_loss=0.4960\n",
      "Step 490: forget_loss=9.1890, retain_loss=1.2454\n",
      "Step 500: forget_loss=13.4686, retain_loss=1.5512\n",
      "Step 510: forget_loss=13.7761, retain_loss=0.8808\n",
      "Step 520: forget_loss=13.2705, retain_loss=0.4501\n",
      "Step 530: forget_loss=7.4253, retain_loss=0.9587\n",
      "Step 540: forget_loss=12.1238, retain_loss=1.1962\n",
      "Step 550: forget_loss=14.0145, retain_loss=0.7318\n",
      "Step 560: forget_loss=13.5601, retain_loss=0.9141\n",
      "Step 570: forget_loss=14.8743, retain_loss=2.5188\n",
      "Step 580: forget_loss=9.8117, retain_loss=0.5508\n",
      "Step 590: forget_loss=13.3690, retain_loss=0.6817\n",
      "Step 600: forget_loss=10.2974, retain_loss=0.6369\n",
      "Step 610: forget_loss=14.2886, retain_loss=0.5266\n",
      "Step 620: forget_loss=5.0764, retain_loss=0.4432\n",
      "Step 630: forget_loss=12.5313, retain_loss=0.6480\n",
      "Step 640: forget_loss=3.6278, retain_loss=0.5261\n",
      "Step 650: forget_loss=11.5970, retain_loss=0.9515\n",
      "Step 660: forget_loss=2.1415, retain_loss=0.4612\n",
      "Step 670: forget_loss=3.2602, retain_loss=0.4660\n",
      "Step 680: forget_loss=12.9379, retain_loss=0.1784\n",
      "Step 690: forget_loss=5.3578, retain_loss=0.6309\n",
      "Step 700: forget_loss=14.3680, retain_loss=0.2449\n",
      "Step 710: forget_loss=14.4571, retain_loss=0.2256\n",
      "Step 720: forget_loss=15.6539, retain_loss=0.2845\n",
      "Step 730: forget_loss=14.5081, retain_loss=1.4912\n",
      "Step 740: forget_loss=14.3660, retain_loss=1.6909\n",
      "Step 750: forget_loss=14.3606, retain_loss=0.2099\n",
      "Step 760: forget_loss=3.3900, retain_loss=1.7447\n",
      "Step 770: forget_loss=3.8908, retain_loss=0.4642\n",
      "Step 780: forget_loss=11.8322, retain_loss=0.1595\n",
      "Step 790: forget_loss=14.2712, retain_loss=0.3799\n",
      "Step 800: forget_loss=15.3115, retain_loss=0.2588\n",
      "Step 810: forget_loss=14.9620, retain_loss=0.4637\n",
      "Step 820: forget_loss=15.2004, retain_loss=0.4230\n",
      "Step 830: forget_loss=14.8628, retain_loss=0.3671\n",
      "Step 840: forget_loss=14.6811, retain_loss=0.3032\n",
      "Step 850: forget_loss=14.4680, retain_loss=0.1940\n",
      "Step 860: forget_loss=15.3972, retain_loss=0.4973\n",
      "Step 870: forget_loss=13.1553, retain_loss=0.3082\n",
      "Step 880: forget_loss=13.3175, retain_loss=0.2866\n",
      "Step 890: forget_loss=14.9537, retain_loss=1.3578\n",
      "Step 900: forget_loss=3.8599, retain_loss=0.2657\n",
      "Step 910: forget_loss=14.9545, retain_loss=0.3187\n",
      "Step 920: forget_loss=14.9037, retain_loss=0.4542\n",
      "Step 930: forget_loss=6.2635, retain_loss=0.3151\n",
      "Step 940: forget_loss=6.9719, retain_loss=0.2099\n",
      "Step 950: forget_loss=14.9934, retain_loss=0.1538\n",
      "Step 960: forget_loss=15.2268, retain_loss=0.1362\n",
      "Step 970: forget_loss=4.8300, retain_loss=0.9538\n",
      "Step 980: forget_loss=14.6485, retain_loss=0.1494\n",
      "Step 990: forget_loss=14.6270, retain_loss=0.1676\n",
      "Step 1000: forget_loss=16.6980, retain_loss=0.3062\n",
      "Step 1010: forget_loss=14.1094, retain_loss=0.1616\n",
      "Step 1020: forget_loss=14.9659, retain_loss=0.1343\n",
      "Step 1030: forget_loss=6.2641, retain_loss=1.3498\n",
      "Step 1040: forget_loss=14.6578, retain_loss=0.2630\n",
      "Step 1050: forget_loss=15.4857, retain_loss=0.2031\n",
      "Step 1060: forget_loss=6.4660, retain_loss=0.1196\n",
      "Step 1070: forget_loss=7.8496, retain_loss=0.2685\n",
      "Step 1080: forget_loss=14.2326, retain_loss=0.1158\n",
      "Step 1090: forget_loss=14.5381, retain_loss=0.1365\n",
      "Step 1100: forget_loss=15.2608, retain_loss=0.1708\n",
      "Step 1110: forget_loss=4.6539, retain_loss=0.1437\n",
      "Epoch 1/3\n",
      "Average Forget Loss: 9.3476\n",
      "Average Retain Loss: 1.8520\n",
      "Step 10: forget_loss=3.5606, retain_loss=0.1435\n",
      "Step 20: forget_loss=14.6867, retain_loss=0.1205\n",
      "Step 30: forget_loss=15.8006, retain_loss=0.1797\n",
      "Step 40: forget_loss=13.5883, retain_loss=0.1277\n",
      "Step 50: forget_loss=16.0667, retain_loss=0.2336\n",
      "Step 60: forget_loss=16.7607, retain_loss=0.4067\n",
      "Step 70: forget_loss=15.6999, retain_loss=0.6918\n",
      "Step 80: forget_loss=15.5626, retain_loss=0.1042\n",
      "Step 90: forget_loss=3.7031, retain_loss=0.1576\n",
      "Step 100: forget_loss=14.1866, retain_loss=1.9977\n",
      "Step 110: forget_loss=14.9304, retain_loss=0.1912\n",
      "Step 120: forget_loss=2.4121, retain_loss=0.1710\n",
      "Step 130: forget_loss=15.0810, retain_loss=0.1541\n",
      "Step 140: forget_loss=14.0824, retain_loss=0.1239\n",
      "Step 150: forget_loss=4.5789, retain_loss=0.1106\n",
      "Step 160: forget_loss=4.8292, retain_loss=0.1350\n",
      "Step 170: forget_loss=13.3330, retain_loss=0.1530\n",
      "Step 180: forget_loss=12.1893, retain_loss=0.1600\n",
      "Step 190: forget_loss=3.2217, retain_loss=0.1234\n",
      "Step 200: forget_loss=14.9057, retain_loss=0.1622\n",
      "Step 210: forget_loss=15.1787, retain_loss=0.1613\n",
      "Step 220: forget_loss=15.0696, retain_loss=0.1066\n",
      "Step 230: forget_loss=14.5183, retain_loss=0.4623\n",
      "Step 240: forget_loss=15.4416, retain_loss=0.1280\n",
      "Step 250: forget_loss=15.6688, retain_loss=0.2122\n",
      "Step 260: forget_loss=4.3369, retain_loss=0.2169\n",
      "Step 270: forget_loss=13.2652, retain_loss=0.1597\n",
      "Step 280: forget_loss=14.7669, retain_loss=0.1076\n",
      "Step 290: forget_loss=15.0923, retain_loss=0.1292\n",
      "Step 300: forget_loss=15.5785, retain_loss=0.0968\n",
      "Step 310: forget_loss=12.6682, retain_loss=0.1104\n",
      "Step 320: forget_loss=4.7272, retain_loss=0.1537\n",
      "Step 330: forget_loss=14.5279, retain_loss=0.1566\n",
      "Step 340: forget_loss=3.7810, retain_loss=0.2391\n",
      "Step 350: forget_loss=14.3330, retain_loss=0.3104\n",
      "Step 360: forget_loss=15.3464, retain_loss=0.1044\n",
      "Step 370: forget_loss=4.3018, retain_loss=0.1287\n",
      "Step 380: forget_loss=14.5749, retain_loss=0.1739\n",
      "Step 390: forget_loss=15.2637, retain_loss=0.1251\n",
      "Step 400: forget_loss=15.0610, retain_loss=0.1841\n",
      "Step 410: forget_loss=13.7687, retain_loss=0.1105\n",
      "Step 420: forget_loss=15.1449, retain_loss=0.0962\n",
      "Step 430: forget_loss=15.0988, retain_loss=0.1397\n",
      "Step 440: forget_loss=15.4326, retain_loss=0.1231\n",
      "Step 450: forget_loss=16.2740, retain_loss=0.1370\n",
      "Step 460: forget_loss=14.0843, retain_loss=0.2313\n",
      "Step 470: forget_loss=15.1549, retain_loss=0.1613\n",
      "Step 480: forget_loss=14.1073, retain_loss=0.2494\n",
      "Step 490: forget_loss=14.0846, retain_loss=0.0861\n",
      "Step 500: forget_loss=14.6552, retain_loss=0.1875\n",
      "Step 510: forget_loss=5.3285, retain_loss=0.1860\n",
      "Step 520: forget_loss=15.8058, retain_loss=0.1065\n",
      "Step 530: forget_loss=15.4252, retain_loss=0.1075\n",
      "Step 540: forget_loss=13.9411, retain_loss=0.1063\n",
      "Step 550: forget_loss=6.0880, retain_loss=0.1127\n",
      "Step 560: forget_loss=16.4799, retain_loss=0.1034\n",
      "Step 570: forget_loss=15.6205, retain_loss=0.0985\n",
      "Step 580: forget_loss=15.1489, retain_loss=0.1254\n",
      "Step 590: forget_loss=14.7967, retain_loss=0.1402\n",
      "Step 600: forget_loss=14.8819, retain_loss=0.1221\n",
      "Step 610: forget_loss=15.6087, retain_loss=0.1904\n",
      "Step 620: forget_loss=15.8141, retain_loss=0.5059\n",
      "Step 630: forget_loss=13.4979, retain_loss=0.1302\n",
      "Step 640: forget_loss=15.6730, retain_loss=0.1369\n",
      "Step 650: forget_loss=15.2890, retain_loss=0.0948\n",
      "Step 660: forget_loss=5.2031, retain_loss=0.5826\n",
      "Step 670: forget_loss=15.3719, retain_loss=0.1075\n",
      "Step 680: forget_loss=14.6226, retain_loss=0.0978\n",
      "Step 690: forget_loss=15.1264, retain_loss=0.1109\n",
      "Step 700: forget_loss=14.5538, retain_loss=0.1151\n",
      "Step 710: forget_loss=15.2551, retain_loss=0.4764\n",
      "Step 720: forget_loss=13.7938, retain_loss=0.0799\n",
      "Step 730: forget_loss=6.9256, retain_loss=0.1379\n",
      "Step 740: forget_loss=15.2293, retain_loss=0.1122\n",
      "Step 750: forget_loss=15.3076, retain_loss=0.1250\n",
      "Step 760: forget_loss=15.0936, retain_loss=0.1111\n",
      "Step 770: forget_loss=3.8784, retain_loss=0.2214\n",
      "Step 780: forget_loss=15.5275, retain_loss=0.6545\n",
      "Step 790: forget_loss=14.9969, retain_loss=0.1588\n",
      "Step 800: forget_loss=15.7682, retain_loss=0.5887\n",
      "Step 810: forget_loss=14.3284, retain_loss=0.1259\n",
      "Step 820: forget_loss=15.9015, retain_loss=0.2093\n",
      "Step 830: forget_loss=14.6943, retain_loss=0.9951\n",
      "Step 840: forget_loss=4.5738, retain_loss=0.3203\n",
      "Step 850: forget_loss=14.3733, retain_loss=0.1299\n",
      "Step 860: forget_loss=2.3263, retain_loss=0.0871\n",
      "Step 870: forget_loss=15.6590, retain_loss=0.1178\n",
      "Step 880: forget_loss=14.9866, retain_loss=0.1247\n",
      "Step 890: forget_loss=5.2196, retain_loss=0.0978\n",
      "Step 900: forget_loss=16.3501, retain_loss=0.1446\n",
      "Step 910: forget_loss=7.5087, retain_loss=0.0941\n",
      "Step 920: forget_loss=15.3460, retain_loss=0.5100\n",
      "Step 930: forget_loss=16.1716, retain_loss=0.2109\n",
      "Step 940: forget_loss=13.5492, retain_loss=0.1146\n",
      "Step 950: forget_loss=15.2356, retain_loss=0.0930\n",
      "Step 960: forget_loss=15.7407, retain_loss=0.1380\n",
      "Step 970: forget_loss=14.9838, retain_loss=0.0888\n",
      "Step 980: forget_loss=14.0171, retain_loss=0.1167\n",
      "Step 990: forget_loss=15.2160, retain_loss=0.1090\n",
      "Step 1000: forget_loss=5.0479, retain_loss=0.2286\n",
      "Step 1010: forget_loss=13.6039, retain_loss=0.0854\n",
      "Step 1020: forget_loss=1.6235, retain_loss=0.1085\n",
      "Step 1030: forget_loss=5.8800, retain_loss=0.1185\n",
      "Step 1040: forget_loss=16.2371, retain_loss=0.1284\n",
      "Step 1050: forget_loss=16.2180, retain_loss=0.2411\n",
      "Step 1060: forget_loss=14.2457, retain_loss=0.0898\n",
      "Step 1070: forget_loss=15.3538, retain_loss=0.7076\n",
      "Step 1080: forget_loss=4.5702, retain_loss=0.1186\n",
      "Step 1090: forget_loss=16.2751, retain_loss=0.0977\n",
      "Step 1100: forget_loss=15.3765, retain_loss=0.0977\n",
      "Step 1110: forget_loss=14.9698, retain_loss=0.1162\n",
      "Epoch 2/3\n",
      "Average Forget Loss: 12.6792\n",
      "Average Retain Loss: 0.1868\n",
      "Step 10: forget_loss=14.1326, retain_loss=0.0963\n",
      "Step 20: forget_loss=15.0646, retain_loss=0.0954\n",
      "Step 30: forget_loss=16.1883, retain_loss=0.1034\n",
      "Step 40: forget_loss=15.2076, retain_loss=0.0923\n",
      "Step 50: forget_loss=15.1956, retain_loss=0.0863\n",
      "Step 60: forget_loss=15.0369, retain_loss=0.0803\n",
      "Step 70: forget_loss=14.9694, retain_loss=0.0888\n",
      "Step 80: forget_loss=2.9895, retain_loss=0.0855\n",
      "Step 90: forget_loss=6.0245, retain_loss=0.1006\n",
      "Step 100: forget_loss=14.9384, retain_loss=0.4202\n",
      "Step 110: forget_loss=9.2021, retain_loss=0.0853\n",
      "Step 120: forget_loss=15.8133, retain_loss=0.0991\n",
      "Step 130: forget_loss=15.5652, retain_loss=0.1518\n",
      "Step 140: forget_loss=13.7145, retain_loss=0.1112\n",
      "Step 150: forget_loss=14.4839, retain_loss=0.0847\n",
      "Step 160: forget_loss=14.0378, retain_loss=0.0868\n",
      "Step 170: forget_loss=15.5168, retain_loss=0.0813\n",
      "Step 180: forget_loss=15.1743, retain_loss=0.0926\n",
      "Step 190: forget_loss=15.0810, retain_loss=0.1131\n",
      "Step 200: forget_loss=15.4442, retain_loss=0.0853\n",
      "Step 210: forget_loss=3.3127, retain_loss=0.0887\n",
      "Step 220: forget_loss=16.4168, retain_loss=0.1035\n",
      "Step 230: forget_loss=15.6110, retain_loss=0.3724\n",
      "Step 240: forget_loss=15.2800, retain_loss=0.0895\n",
      "Step 250: forget_loss=15.8001, retain_loss=0.2402\n",
      "Step 260: forget_loss=14.7645, retain_loss=0.1143\n",
      "Step 270: forget_loss=14.9947, retain_loss=0.3363\n",
      "Step 280: forget_loss=16.5835, retain_loss=0.0891\n",
      "Step 290: forget_loss=15.1280, retain_loss=0.0897\n",
      "Step 300: forget_loss=4.2397, retain_loss=0.0950\n",
      "Step 310: forget_loss=15.0423, retain_loss=0.2656\n",
      "Step 320: forget_loss=14.6427, retain_loss=0.1046\n",
      "Step 330: forget_loss=14.5429, retain_loss=0.2198\n",
      "Step 340: forget_loss=15.1591, retain_loss=0.0988\n",
      "Step 350: forget_loss=14.1289, retain_loss=0.1549\n",
      "Step 360: forget_loss=15.3829, retain_loss=0.0682\n",
      "Step 370: forget_loss=15.0343, retain_loss=0.0876\n",
      "Step 380: forget_loss=16.5614, retain_loss=0.1080\n",
      "Step 390: forget_loss=14.4132, retain_loss=0.0957\n",
      "Step 400: forget_loss=13.7014, retain_loss=0.1159\n",
      "Step 410: forget_loss=13.5777, retain_loss=0.0728\n",
      "Step 420: forget_loss=14.0051, retain_loss=0.1044\n",
      "Step 430: forget_loss=14.3745, retain_loss=0.0840\n",
      "Step 440: forget_loss=4.8761, retain_loss=0.0930\n",
      "Step 450: forget_loss=14.7641, retain_loss=0.0898\n",
      "Step 460: forget_loss=15.6809, retain_loss=0.0878\n",
      "Step 470: forget_loss=15.3334, retain_loss=0.0692\n",
      "Step 480: forget_loss=15.5774, retain_loss=0.0825\n",
      "Step 490: forget_loss=3.8957, retain_loss=0.0819\n",
      "Step 500: forget_loss=15.1345, retain_loss=0.0944\n",
      "Step 510: forget_loss=15.9138, retain_loss=0.0756\n",
      "Step 520: forget_loss=15.1708, retain_loss=0.0939\n",
      "Step 530: forget_loss=14.6581, retain_loss=0.0886\n",
      "Step 540: forget_loss=14.7287, retain_loss=0.0817\n",
      "Step 550: forget_loss=15.0046, retain_loss=0.1005\n",
      "Step 560: forget_loss=2.0779, retain_loss=0.1572\n",
      "Step 570: forget_loss=15.7197, retain_loss=0.2055\n",
      "Step 580: forget_loss=1.7584, retain_loss=0.1088\n",
      "Step 590: forget_loss=16.0144, retain_loss=0.0947\n",
      "Step 600: forget_loss=14.7178, retain_loss=0.2066\n",
      "Step 610: forget_loss=15.1170, retain_loss=0.0709\n",
      "Step 620: forget_loss=3.4905, retain_loss=0.0748\n",
      "Step 630: forget_loss=14.7584, retain_loss=0.0776\n",
      "Step 640: forget_loss=15.2728, retain_loss=0.0724\n",
      "Step 650: forget_loss=6.8418, retain_loss=0.0804\n",
      "Step 660: forget_loss=13.3482, retain_loss=0.0794\n",
      "Step 670: forget_loss=14.2853, retain_loss=0.0855\n",
      "Step 680: forget_loss=15.4458, retain_loss=0.1285\n",
      "Step 690: forget_loss=15.0927, retain_loss=0.9583\n",
      "Step 700: forget_loss=14.2913, retain_loss=0.0836\n",
      "Step 710: forget_loss=15.0197, retain_loss=0.0750\n",
      "Step 720: forget_loss=14.6067, retain_loss=0.0743\n",
      "Step 730: forget_loss=14.8524, retain_loss=0.0919\n",
      "Step 740: forget_loss=15.1604, retain_loss=0.0830\n",
      "Step 750: forget_loss=15.1925, retain_loss=0.2267\n",
      "Step 760: forget_loss=15.1093, retain_loss=0.0839\n",
      "Step 770: forget_loss=2.1458, retain_loss=0.0940\n",
      "Step 780: forget_loss=14.2663, retain_loss=0.0793\n",
      "Step 790: forget_loss=4.8628, retain_loss=0.0719\n",
      "Step 800: forget_loss=15.7376, retain_loss=0.1584\n",
      "Step 810: forget_loss=14.3013, retain_loss=0.0934\n",
      "Step 820: forget_loss=15.6977, retain_loss=0.0787\n",
      "Step 830: forget_loss=14.5844, retain_loss=0.0969\n",
      "Step 840: forget_loss=16.5810, retain_loss=0.1021\n",
      "Step 850: forget_loss=14.9546, retain_loss=0.0881\n",
      "Step 860: forget_loss=16.1410, retain_loss=0.0985\n",
      "Step 870: forget_loss=14.8847, retain_loss=0.1571\n",
      "Step 880: forget_loss=15.3249, retain_loss=0.0804\n",
      "Step 890: forget_loss=14.5946, retain_loss=0.0799\n",
      "Step 900: forget_loss=14.6927, retain_loss=0.1091\n",
      "Step 910: forget_loss=5.7672, retain_loss=0.0937\n",
      "Step 920: forget_loss=14.9419, retain_loss=0.0867\n",
      "Step 930: forget_loss=15.0462, retain_loss=0.0864\n",
      "Step 940: forget_loss=5.0841, retain_loss=0.0864\n",
      "Step 950: forget_loss=15.0712, retain_loss=0.1116\n",
      "Step 960: forget_loss=15.0678, retain_loss=0.0865\n",
      "Step 970: forget_loss=15.1206, retain_loss=0.1247\n",
      "Step 980: forget_loss=15.1353, retain_loss=0.0753\n",
      "Step 990: forget_loss=15.7469, retain_loss=0.0762\n",
      "Step 1000: forget_loss=14.8530, retain_loss=0.0756\n",
      "Step 1010: forget_loss=14.8747, retain_loss=0.0756\n",
      "Step 1020: forget_loss=13.9778, retain_loss=0.0786\n",
      "Step 1030: forget_loss=7.3086, retain_loss=0.0853\n",
      "Step 1040: forget_loss=7.5258, retain_loss=0.0753\n",
      "Step 1050: forget_loss=14.8668, retain_loss=0.1033\n",
      "Step 1060: forget_loss=15.5655, retain_loss=0.0926\n",
      "Step 1070: forget_loss=15.2402, retain_loss=0.0765\n",
      "Step 1080: forget_loss=15.2939, retain_loss=0.1012\n",
      "Step 1090: forget_loss=15.0102, retain_loss=0.0817\n",
      "Step 1100: forget_loss=14.2458, retain_loss=0.0913\n",
      "Step 1110: forget_loss=15.8319, retain_loss=0.1992\n",
      "Epoch 3/3\n",
      "Average Forget Loss: 12.8458\n",
      "Average Retain Loss: 0.1184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'semeval25-unlearning-model'\n",
    "    tokenizer_name = 'allenai/OLMo-1B-0724-hf'\n",
    "    retain_path = \"/teamspace/studios/this_studio/train/retain.jsonl\"\n",
    "    forget_path = \"/teamspace/studios/this_studio/train/forget.jsonl\"\n",
    "\n",
    "    try:\n",
    "        model, reference_model, tokenizer, retain_loader, forget_loader = setup_unlearning(\n",
    "            model_path=model_path,\n",
    "            tokenizer_name=tokenizer_name,\n",
    "            retain_path=retain_path,\n",
    "            forget_path=forget_path,\n",
    "            batch_size=1\n",
    "        )\n",
    "\n",
    "        unlearner = EnhancedUnlearning(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            reference_model=reference_model,\n",
    "            beta=1.0,\n",
    "            memory_bank_size=1000\n",
    "        )\n",
    "\n",
    "        unlearner.unlearn(\n",
    "            forget_loader=forget_loader,\n",
    "            retain_loader=retain_loader,\n",
    "            num_epochs=3,\n",
    "            learning_rate=1e-5,\n",
    "            output_path=\"./unlearned_model\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during setup or training: {str(e)}\")\n",
    "        print(\"\\nDebugging information:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
